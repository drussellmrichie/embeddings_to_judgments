{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "warnings.simplefilter(\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['brand', 'good', 'trait', 'food', 'occupation', 'risk', 'people']\n",
    "dims = [('sincere','exciting'),\n",
    "        ('hedonic','utilitarian'),\n",
    "        ('masculine','feminine'),\n",
    "        ('tasty','nutritious'),\n",
    "        ('significance','autonomy'),\n",
    "        ('dread-inducing','unknowable'),\n",
    "        ('warm', 'competent')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dict_of_Xs.pickle\", \"rb\") as handle:\n",
    "    dict_of_Xs = pickle.load(handle)\n",
    "with open(\"data/dict_of_ys.pickle\", \"rb\") as handle:\n",
    "    dict_of_ys = pickle.load(handle)\n",
    "\n",
    "# with open(\"data/dict_of_glove_Xs.pickle\", \"rb\") as handle:\n",
    "#     dict_of_Xs = pickle.load(handle)        \n",
    "# with open(\"data/dict_of_glove_ys.pickle\", \"rb\") as handle:\n",
    "#     dict_of_ys = pickle.load(handle)\n",
    "\n",
    "# with open(\"data/dict_of_swow_Xs.pickle\", \"rb\") as handle:\n",
    "#     dict_of_Xs = pickle.load(handle)\n",
    "    \n",
    "# with open(\"data/dict_of_swow_ys.pickle\", \"rb\") as handle:\n",
    "#     dict_of_ys = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_Xs['brand'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_ys['sincere']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dimension-specific distributions of percentage of items not rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_missing = pd.DataFrame([(dim, 200 - df.shape[0]) for dim, df in dict_of_ys.items()], \n",
    "                             columns=['dim','missing_items'])\n",
    "mean_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_missing.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From prereg:\n",
    "\n",
    "> We will use the 300-dimensional word2vec vectors for each judgment target to predict the mean judgment ratings with ridge, lasso, support vector (SVR, with radial basis function, polynomial, and sigmoid kernels), and k-nearest neighbors (KNN) regression (all techniques as implemented in Scikit-Learn).\n",
    "\n",
    "> For each judgment target, model fit will be assessed by training each model on a random 90% of the data, computing r-squared on the remaining 10%, and repeating this procedure 1000 times, to obtain an average out-of-sample r-squared on different test-train splits. For support vector, lasso, and ridge regressions, we will perform the above procedure once for each of the following values of the hyperparameter c: {10^-2, 10^-1, 10^0, 10^1, 10^2, 10^3, 10^4, 10^5, 10^6, 10^7}. For KNN regression, we will perform the above procedure once for each of the following values of the hyperparameter k: {1,2,3,...10}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list = [(LinearRegression,    'ols'),\n",
    "model_list = [\n",
    "              (SVR,                 'svr'),\n",
    "              (Ridge,               'ridge'),\n",
    "              (Lasso,               'lasso'), \n",
    "              (KNeighborsRegressor, 'knn')\n",
    "               ]\n",
    "\n",
    "# arg_dicts_by_model = [\n",
    "#                          [{'fit_intercept':True}],\n",
    "arg_dicts_by_model = [\n",
    "                         [{'C':10**x}       for x in range(-2,8)],\n",
    "                         [{'alpha':10**x}   for x in range(-2,8)],\n",
    "                         [{'alpha':10**x}   for x in range(-2,8)],\n",
    "#                          [{'alpha':10**x}   for x in np.linspace(-2,0,10)],   # for additional explo of lasso\n",
    "#                          [{'alpha':10**x}   for x in np.linspace(-.9,-.4,10)],  # for additional explo of lasso\n",
    "                         [{'n_neighbors':x} for x in range(1,11)]\n",
    "                      ]\n",
    "\n",
    "# if you just want to run ridge\n",
    "# model_list = [(Ridge, 'ridge')]\n",
    "\n",
    "# arg_dicts_by_model = [\n",
    "#                         [{'alpha':10}]\n",
    "# ]\n",
    "\n",
    "\n",
    "# because I forgot to run SVR with these two kernels initially....\n",
    "\n",
    "# model_list = [(SVR, 'svr'),\n",
    "#               (SVR, 'svr')]\n",
    "\n",
    "# arg_dicts_by_model = [\n",
    "#                          [{'kernel':'poly',    'C':10**x} for x in range(-2,8)],\n",
    "#                          [{'kernel':'sigmoid', 'C':10**x} for x in range(-2,8)],\n",
    "#                       ]\n",
    "\n",
    "# kernels = ['poly', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_train_splits = 100 # TO TEST THIS CODE MORE QUICKLY, SET THIS VALUE CLOSER TO 5 OR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names_flattened = [x for dim_pair in dims for x in dim_pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_score(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_test_train_splits(arg_dict):\n",
    "    rsquareds = []\n",
    "    rmses = []\n",
    "    # copy vecs_and_judgment because each process of this function will modify it,\n",
    "    # and changing the original might lead to unwanted behavior\n",
    "    # I think the behavior can be replaced by the randomization of train_test_split, but I think I \n",
    "    # was getting weird behavior with that....\n",
    "    vecs_and_judgment_temp = vecs_and_judgment.copy(deep=True)\n",
    "    for _ in range(n_test_train_splits):\n",
    "        vecs_and_judgment_temp = vecs_and_judgment_temp.sample(frac=1)\n",
    "#         X = vecs_and_judgment_temp.iloc[:,:300]\n",
    "        X = vecs_and_judgment_temp.iloc[:,:-1]\n",
    "        y = vecs_and_judgment_temp['judgment']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "        regression = model(**arg_dict) # refers to, e.g., svr(C=.01)\n",
    "        regression.fit(X=X_train, y=y_train)\n",
    "        y_pred = regression.predict(X=X_test)\n",
    "        rsquared = r2_score(y_test, y_pred)\n",
    "        rmse     = rmse_score(y_test, y_pred)\n",
    "        \n",
    "        rsquareds.append(rsquared)\n",
    "        rmses.append(rmse)\n",
    "    mean_rsquared = np.mean(rsquareds)\n",
    "    mean_rmses = np.mean(rmses)\n",
    "    return mean_rsquared, mean_rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forgot to include the last two SVR models/kernels when I initially wrote this code, and my rewrite with that in mind required saving the files in a new way. So, you'll need to change the commenting of the first line and the last lines in the code below depending on whether you want to run SVR-poly and SVR-sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, list_of_arg_dicts in zip(model_list, arg_dicts_by_model):\n",
    "# for model, list_of_arg_dicts, kernel in zip(model_list, arg_dicts_by_model, kernels):\n",
    "    model, model_name = model\n",
    "    print(model_name)\n",
    "    model_results = []\n",
    "    for domain, dim_pair in zip(domains, dims):\n",
    "        for dim in dim_pair:\n",
    "            print('\\t', dim)\n",
    "            X = dict_of_Xs[domain]\n",
    "            y = dict_of_ys[dim]\n",
    "            vecs_and_judgment = pd.concat([X,y], axis=1)\n",
    "            with Pool() as p:\n",
    "                scores_by_hyperparam = [mean_scores for mean_scores in p.map(many_test_train_splits, list_of_arg_dicts)]\n",
    "            model_results.append(scores_by_hyperparam)\n",
    "    model_results = pd.DataFrame(data=model_results, index=dim_names_flattened, columns=list_of_arg_dicts).T\n",
    "    rsquared_df = model_results.applymap(lambda x: x[0])\n",
    "    rmse_df     = model_results.applymap(lambda x: x[1])\n",
    "    \n",
    "    rsquared_df.to_csv(f'results/preregistered_models/rsquared/{model_name}_all_judgments.csv', float_format='%.2f')\n",
    "    rmse_df.to_csv(    f'results/preregistered_models/rmse/{model_name}_all_judgments.csv',     float_format='%.2f')\n",
    "#     rsquared_df.to_csv(f'results/preregistered_models/rsquared/{model_name}_{kernel}_all_judgments.csv', float_format='%.2f')\n",
    "#     rmse_df.to_csv(    f'results/preregistered_models/rmse/{model_name}_{kernel}_all_judgments.csv',     float_format='%.2f')\n",
    "\n",
    "#     rsquared_df.to_csv(f'results/preregistered_models_glove/rsquared/{model_name}_all_judgments.csv', float_format='%.2f')\n",
    "#     rmse_df.to_csv(    f'results/preregistered_models_glove/rmse/{model_name}_all_judgments.csv',     float_format='%.2f')\n",
    "#     rsquared_df.to_csv(f'results/preregistered_models_glove/rsquared/{model_name}_{kernel}_all_judgments.csv', float_format='%.2f')\n",
    "#     rmse_df.to_csv(    f'results/preregistered_models_glove/rmse/{model_name}_{kernel}_all_judgments.csv',     float_format='%.2f')\n",
    "    \n",
    "#     rsquared_df.to_csv(f'results/preregistered_models_swow/rsquared/{model_name}_all_judgments.csv', float_format='%.2f')\n",
    "#     rmse_df.to_csv(    f'results/preregistered_models_swow/rmse/{model_name}_all_judgments.csv',     float_format='%.2f')\n",
    "#     rsquared_df.to_csv(f'results/preregistered_models_swow/rsquared/{model_name}_{kernel}_all_judgments.csv', float_format='%.2f')\n",
    "#     rmse_df.to_csv(    f'results/preregistered_models_swow/rmse/{model_name}_{kernel}_all_judgments.csv',     float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
